Clojure Graphs

# Intro

Good afternoon people, I'm glad to be here with all of you in this lovely city that is Amsterdam. My name is Wilker, I live in SÃ£o Paulo, and I work for a company called Nubank, we are bringing modern financial services for millions of brazilians.

The title of my presentation is Clojure Graphs, but to get there, I first like to talk with about information access.

# The problem

I've done lots of client applications in my life, and fetching data has always been a painful part of the process. It always seems to start simple, just call this endpoint, get this, maybe a single extra one... But as the time goes, the data fetching code tends to grow and grow, at some point you need to parallelize to make it fast, with that comes a lot of complex and error prone code for orchestrating the requests.

# Present exercise

Let's take this popular layout that I guess most people here will be familiar with: a Youtube video page. Let's consider the information required to display this page (This is a feature complete, just picking enough items to illustrate the case).

* We need the video title
* The video description
* The channel name
* The video comments
* From each video comment we need the channel name and comment text
* Also there is a relationship that tells which is the next video

A first thing to notice is that, even on a simple layout like this, we need many different resources. The different colors mark what different namespaces of how we break down the entities.

Let's see how we can provide this data through a REST API.

# The REST model

First, we have to load the video resource, do to that we can make an HTTP request for the URL "/video/1", this will give us the src, the title, and the video description. The channel is a different resource, so now we have to make a follow-up request to get its name. The comments are also a different resource, this time we have a one to many situations.

With another request, we can get those, and if we are purist about the REST, an extra request per comment will be necessary to get the author name for each comment.

And to finish up, we have a relation to the next video; this adds more two requests, one for the video and one for the channel.

So your client has to know how to fetch each of those things, it might need to make parallel requests to make it fast, so you add a fair amount of complexity to manage these resources. And each different client you have has to do the same.

Let's see how the actual Youtube API implements it.

This is a screen shot extracted from the Youtube API documentation, it tells you the "parts" available to read from a video resource.

The Youtube API made this convention that for every resource you have to specify a "part" parameter, which will dictate which groups of attributes we get from that resource. So this list on the bottom contains the available parts. From this list, can you tell me in which group/groups the information we need is present?

If you think "snippet" you got it right (or if you read the description text above which tells it). So now its part of the API designer at Google to define which how many groups are optimal, remember that if you need just one attribute for the group, you still have to get the whole group.

I'm not trying to be picky on Youtube; the people who made those APIs are smart ones, this is just a few examples of types of hacks we resort due to the limitations of the structures we are using.

Let's take a look in a different API, the Facebook API.

The official Facebook Graph API still doesn't use GraphQL, but they allow for a sophisticated field definition on the URL, this is what it looks like:

"/me?fields=name,friends{name,friends{name}}"

This is saying, from me, load my name and my friends names, and names of friends of friends.

Cool, but again we see more hacks on top of the thing, giving more signals that the protocol wasn't expressive enough, just asking for resources in the REST way forces every API designer to come with its own set to tricks to overcome fundamental daily problems.

I've tried Swagger, Hypermedia, JSON Schema, and many other ideas around these APIs; they didn't seem to fix the problem, and since every REST API has its quirks, they are hard to compose.

# Graphql is released

But then Facebook released GraphQL to the public.

GraphQL looks like a mature and optimized version of what their previous Graph API looked. The GraphQL API had some essential features that made the difference:

1. Attribute-oriented: you specify each attribute you need
2. Composition: you were able to keep nesting the query request
3. Introspection: you can explore the API dynamically

You may agree with me that's a lot of features to live in a single URL line. To demo the difference, this is our previous line; and here is it in GraphQL:

As you can see, the first exciting thing is getting rid of all those commas. Another difference is that now it always goes in a POST request, which removes some constraints like URL's max 2 MB size on some browsers. And of course, tune the syntax, thinking now in a more sophisticated language. The next significant improvement is bringing introspection as a built-in feature. Instead of relying on documentation, the system can describe itself, giving the users exploratory capabilities.

If you for example access the explorer for the Github GraphQL API (and any GraphQL API can output that), you can start guessing for names, or just scrolling to the suggestion list, and you can probably find what you are looking for.

Let's see how GraphQL could handle our initial query problem:

# The GraphQL model

First we have to describe a schema for the data. We can start by the video type. The video type will have an id, a title, a description, a channel (which is another type), a list of comments and a link to the next video.

Then we can declare the channel as so. And finally the comment (for simplification here, let's say the comment author is always a channel).

Now with schema on hand, time to write the query.

We start with a query expression. First we have to access our video node, we can use a query with params to request it. Then it's time to start asking for data, we can get the id, the title. Now on the channel, we can use the association and nest a query requesting it's title right away, no more breaking requests. Then comes the description, the comments (which can again nest, and nest again for the author there). And finally the next video.

Now with a single payload, we can express the data requirements for the entire page. This is major! Now we don't have to change our server JSON output every time our UI decide to change. The server can focus on making things available, instead of trying to guess what combinations of data are going to be useful, just provide then all and let the client decide.

And if you organize your components right, the structure will have a good match with the UI component structure. Instead of having to issue and coordinate many requests, you can make one that will come with the data just like you need it, how convenient.

# The clojure way

That's all great, but how about Clojure? How can we use those ideas in the language we love? Let's recap some of the characteristics that make this system suitable:

1. Attribute-oriented: you specify each attribute you need
2. Composition: you were able to keep nesting the query request
3. Introspection: you can explore the API independent of its documentation, information about the data is part of the process

Can you think of something on Clojure that fits those? Who here uses Datomic? What about the pull syntax on it? Yes, the Datomic pull syntax covers the attribute oriented and composition requires, using just EDN!

Here is how we can express the same data requirements as we did in the Facebook Graph API, but with EDN:

Let's walk it step by step. First we start with a blank query on both sides, on Clojure side this means an empty vector. Then we add "me" to the query, a simple attribute. Then we make a join on it, on the GraphQL we use the classic brackets after the attribute, the EDN use a more Lispy style, we transform it into a Clojure map, where the key is the attribute, and the value is a new empty vector, so we can start it over again. The we ask for the friends name, then the friends friends. Time to another join, can you see it? And we go on and finish it.

Most of us probably can read the GraphQL version easier, looks so much like all C notation things we have been reading for quite a time.  But I like the fact that we can have the same level of expressiveness using just Clojure data structures, this means we don't need a new parser to read it, neither a new set of primitives to work with, you have the entire Clojure toolset to do it!

I hope I can demonstrate to you at this point that we are at least on the same level as GraphQL is. The next step is: what can Clojure add to this system, what is a good Clojure idea that we can bring to this mix?

The most impactful things I have learned about designing information systems with Clojure came from Datomic and Spec. And this lesson can be summarized as "context-free attributes are king."

# The value of labels

If I give you this data: {:id "..."}, what can you infer from this label? Probably nothing, the reason been that `:id` is too much a generic thing, sure we can infer it's some identifier, but where it's semantically accepted? Where can we use it? To answer this question just `:id` is not enough.

What about {:movie/id "..."}? Well, this is better, now our space gets reduced, but still kind hard to figure where we can use this, is there a global movie identifier standard where this ID might belong, I'm not sure, but instead of the whole world of ids, now we are limited to movie ids.

And what if it looked like this: {:imdb.movie/id "..."}? Now it seems evident to me; it's an id from the IMDB website; if I get that information and throw in their API, or movie URL I can expect to get something. So we went from a generic value that we don't say much about, to something we can use and specify. By narrowing the scope of the label, we can spec more of it.

With small labels you always have to answer a second question: "where am I?". You look at a `:id`, and you have to know in a different step, id of which kind? It's at least a two-step process.

It makes sense when we read, because we always read the type name first, like: "Ok, I got a User, now it contains: id, name, title..." But if we send that plain map, the information is lost. This is way type systems always have to know the type. Otherwise, the ambiguity would kill then.

This is why spec by design doesn't allow you to define shapes, by doing it you have the context dependency for your attributes.

Using long enough labels to be context-free, takes all these problems away. The information is directly there, no more context seeking.

Think like this: when you use a broad, short, nonspecific label, that information requires some out of band context to make sense, by using extended labels we can incorporate the meaning directly, no context required.

As you use bigger labels, they have more space to live, think like this, on small labels their collision rate is very high, so they live fighting and killing each other because they can't co-exist, so to resolve the ambiguity issue we create rules about contexts, that get more and more complex, that we wont need if we just give things different labels. And that's what bigger labels give us, they have more room, they dont collide so easy, they can live happily together.

# Information expansion

Now I want to present you the idea of information expansion, which is like connecting the dots using its current data to expand it, like this: "given that I have this information, what can I reach?".

Let's start basic, given we have no information, let's represent it with a blank Clojure map: "{}"

What can we expand that too? Well, of course, it depends on your system, but a general answer can be: "we can expand to anything that doesn't require any input." Examples can be:

* env information: :myapp.api/shard
* constants: :math/PI
* root entries, things like: :myapp.user/me, :myblog.post/all-posts...

But what if I want some more specific information, like the Youtube video title on our UI demo. Then we need more context; an empty map can't expand to that. But what if we start from this: `{:youtube.video/id "..."}`

Now we can access everything we had before (things without dependencies) plus all the things provided from this Youtube video id, things like: :youtube.video/title :youtube.video/duration, :youtube.video/description

One information that's also part of the video is the channel id, and from that we can expand to every information of that channel as well, like title, customer url. And a channel could have the user id associated with it, enabling us to also bring any user information on the expansion.

This demonstrates how we can leverage the significance of a expressive label to relate information and expand on it.

In short, what I'm trying to say is: "We make relationships out of the labels, not types."

# Introduce Pathom

Now it's time to start the more practical part of this presentation. I hope I was clear enough so you can get the general idea about how we are going to make the information available on our API, though attribute association.

And is using this idea of direct attribute relationships and context expansion that Pathom is built with. Pathom is a library that I've been working for quite some time, ever since I started writing parsers for Om.next at the time (now you guys should totally use Fulcro).

I would like to focus this presentation more on the ideas than on implementation details, so we will jump into how we can use Pathom to implement this attribute connection that we are talking about.

To start, let's see how we can implement the video basic information:

(defonce indexes (atom {}))

First, we define an atom to hold our index, the index for Pathom serves the purpose that Schema serves for GraphQL, but we build it differently.

(defmulti resolver-fn pc/resolver-dispatch)

Then we def a multi-method that will make the dispatch for our resolvers, the resolvers are like the edges of the graph, they know how to navigate through the information.

(def defresolver (pc/resolver-factory resolver-fn indexes))

With the building blocks in hand, we create a helper function to facilitate the creation of resolvers.

Now to our first resolver:

(defresolver `youtube-video-by-id
  {::pc/input  #{:youtube.video/id}
   ::pc/output [:youtube.video/id
                :youtube.video/published-at
                :youtube.video/title
                :youtube.video/description
                :youtube.channel/id
                :youtube.channel/title]}
  (fn [env {:keys [youtube.video/id]}]
    (some-> (youtube env (str "/videos?part=snippet&id=" id))
            :items first
            (adapt-video))))

Let's digest this piece by piece. The first argument we send is the resolver identifier; this is a symbol, it serves to index the resolver itself with its data. The second argument is the data map for that resolver, contains any information we want to attach to it. For this resolver, we set the input and output. The input is a set of attributes, specifying what is required for this resolver to run. The output takes the same form of a query and can be nested. In our case what we want to spit out is this flat structures, with the attributes you are seeing.

We can read this specification as: given a youtube video id, I (resolver) can provide you id, published at, title, description, etc... Or you can also read as if you need a youtube video published at, title, etc. I can give you if you can provide me a Youtube video id.

Then we have the function to implement the resolver. This is always a function with arity two. The first argument contains the environment, it's a map containing all sorts of information about the parsing, like the current entity context, current path, sub-query, etc. The second argument is the input, the keys you made required at `::pc/input`, if you don't ask anything it will be an empty map.

On the implementation, we use the video id to make a request to the Youtube API, then we unwrap the video in the body. The next important step is to adapt the returned keys, we want to turn THIS into THIS. So we now have context free information.

Let's try this out.

Remember we talked about having a context, on the blank query we have no context at all. But in our query syntax, we have a feature to provide a single attribute as context; we use `lookup refs`. Lookup refs are vectors with two elements, where the first element is a keyword. For example, to provide a :youtube.video/id, we can use the following lookup ref: [:youtube.video/id "ID"]. Let's see what we get back when we query for this. As you can see, we have a map with the data we provided.

Now we can make a join on this lookup ref so that we can expand the information for more things. We can, for example, ask for the video title or description. Note the complete options are what we said was available on the output for the video id.

## Seeing the expansion process

I want to explain more how this expansion process works. On the left we have our current entity context, in this example we starting having a youtube video id. On the right side we see the query we are going to process. On the bottom we will see the result getting accumulated as we process the query.

In the first query attribute we ask for the youtube video id. Since this information is already present in our context, we just pull that into the result. Now its time to get the video title, but this information is not present on the context. This will trigger an index lookup, the index will say that it knows how to find a youtube title from a youtube video id, since we have that available, the resolver will be called and the resolver result will be merged with the current context. Now we can extract the video title as well. And we go doing the same until we finish building the output.

## Pulling comments

Now that we understand a bit more about the information expansion, let's introduce a join case, the comments case.

(defresolver `youtube-video-comments
  {::pc/input  #{:youtube.video/id}
   ::pc/output [{:youtube.video/comments [:youtube.comment/like-count
                                          :youtube.comment/published-at
                                          :youtube.comment/can-rate
                                          :youtube.comment/text-display
                                          :youtube.comment/id
                                          :youtube.comment/author-display-name
                                          :youtube.video/id]}]}
  (fn [env {:keys [youtube.video/id]}]
    (some->> (youtube env (str "/commentThreads?part=snippet&videoId=" id))
             :items
             (mapv adapt-comment)
             (hash-map :youtube.video/comments))))

Most of the parts are very similar to our previous resolver. A new thing you can see in the output specification. This time we use a join on video comments, because this is a to-many relationship, so in the end out map will have a youtube video comments key, with a vector of maps inside. Each of these maps will contain the attributes specified in the comments sub-query, this represents the initial context for each attribute there.

Let's test that out.

## Next video

Time to get the next video. Although this is a to-one relationship, we can't merge it in because we have conflicting attributes, so we have to nest it down so we can have a new context space. The Youtube API doesn't have a direct endpoint to get the next video. What we have to do instead is load the related videos and pick the first one there.

We could just write it in a one go resolver, but we benefit more if we do it in steps, the first step is fetching related videos, the second is picking the first out of it. This is how we can write the first resolver:

(defresolver `youtube-video-related
  {::pc/input  #{:youtube.video/id}
   ::pc/output [{:youtube.video/related [:youtube.video/title
                                         :youtube.video/description
                                         :youtube.video/published-at
                                         :youtube.video/id
                                         :youtube.channel/id
                                         :youtube.channel/title]}]}
  (fn [env {:keys [youtube.video/id]}]
    (some->> (youtube env (str "/search?part=snippet&maxResults=25&relatedToVideoId=" id "&type=video"))
             :items
             (mapv adapt-related-video)
             (hash-map :youtube.video/related))))

Very much like the one in comments, we expose a new key containing the vector with related videos.

And now this is how we can implement the next video:

(defresolver `youtube-next-video
  {::pc/input  #{:youtube.video/related}
   ::pc/output [{:youtube.video/next-video [:youtube.video/title
                                            :youtube.video/description
                                            :youtube.video/published-at
                                            :youtube.video/id
                                            :youtube.channel/id
                                            :youtube.channel/title]}]}
  (fn [_ {:keys [youtube.video/related]}]
    {:youtube.video/next-video (first related)}))

We can leverage the video related output directly, just make it a requirement, and the engine will walk it automatically for you. Using that we export a map with the next video label containing the first related item.

And as you can see on the auto-complete, features like related and next video can also be used from the related / next video themselves, given all the requirement is having a youtube video id, which they do.

This is the power the labels can get you, by each having a global meaning by itself, they can be later referenced and walked, you create a system where navigating to each point is a matter of knowing its name.

# Bringing GraphQL to the Mix

All of this is cool, but! Clojure is this niche language, the rest of the world is embracing GraphQL, and no way this people will use this Clojure for their APIs. And I agree with you, its unrealistic to expect then to use Clojure to implement their APIs, GraphQL seems to be here to stay for some time, and we will have to deal with GraphQL APIs anyway.

Whats cool is that, GraphQL has introspection, which means we can predict ahead of time what are valid fields on each position path, huh. What if I try to read it and convert it into the Pathom index format? Well, I have a proof of concept that I like to show to you.

WARNING: experimental features, not recommended for production usage at this point.

Let's say we need to pull some data from the Github API into our system. I'm not explaining much about it now, this is the code for the integration. Now we can pull the index and setup the resolver. Let's try that.

Fetching my own login.

Let's check my pinned repositories. So, in GraphQL we are required to bound the lists, so we have to send a parameter, this is gonna look bad because there is not support por parameters on this UI yet, but works.

# Merging indexes

Now we can combine queries one inside of the other. I can query for a youtube video in the middle of a github item query, or the other way around.

Let's say we have our own database, that can tell the github user that authored a youtube video.

The database is a map from youtube video id to github login.

We then create a resolver to make the translation, since it's such an unusual relation I think its worth to give it a name, this way we know what we are linking into. So we have to output a map that matches our output shape, and here we are.

Let's try this up.

# Universal API

In GraphQL they are already talking about connecting multiple GraphQL endpoints, look for GraphQL Schema Stitching and you will find it out. And they are already talking about merging schemas and so, but there is a caveat for schema merging. This is from a blog post from the guys that make Graph.cool: "QUOTE".

It's a brand new system, and they still have the merging problem.

In our code, we take for granted the namespaces, the power we have that allows to mix many functions from different packages in a single function call, they can live together because each of then has fully qualified symbol name. We can have the same level of power with our attributes, but we need to give then the same namespace treatment we do to our code. Then we could just merge all the APIs and focus on how to use the information instead of spending so much time coordinating its fetching.
